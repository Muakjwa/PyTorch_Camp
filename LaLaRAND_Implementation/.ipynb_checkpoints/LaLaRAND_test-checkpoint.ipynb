{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "168b107f-ddaf-4bdb-a76e-e79d0830eabc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"5\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f31748a-b99b-462d-831f-5c95dd345d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg_weight = torchvision.models.VGG11_Weights.DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c888757b-236c-4ed5-8d06-384bc76a733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = torchvision.models.vgg11(weights=model_vgg_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc595a7-5ac8-4fd1-a2a9-ad1894f95227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8899acd5-f868-47dc-94ab-730d02fceab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "Linear(in_features=25088, out_features=4096, bias=True)\n",
      "ReLU(inplace=True)\n",
      "Dropout(p=0.5, inplace=False)\n",
      "Linear(in_features=4096, out_features=4096, bias=True)\n",
      "ReLU(inplace=True)\n",
      "Dropout(p=0.5, inplace=False)\n",
      "Linear(in_features=4096, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "for name, child in model_vgg.named_children():\n",
    "    if name =='classifier':\n",
    "        print(len(layers))\n",
    "    if (type(child) != torch.nn.modules.container.Sequential):\n",
    "        layers.append(child)\n",
    "    else:\n",
    "        for layer in child:\n",
    "            layers.append(layer)\n",
    "\n",
    "for layer in layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e642d781-0bb1-44fd-ba7c-24bf138eaf35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rinput = torch.randn((1,3,32,32))\n",
    "layers[0](rinput).device == torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28e5355c-d69d-4b2a-9744-af0334d6ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_layers = []\n",
    "for layer in layers:\n",
    "    gpu_layers.append(layer.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d01fe87-45f3-457e-b4c7-4c79c6ac2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b16c272-81bb-466e-a005-a0ff72e898f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaLaRAND():\n",
    "    def __init__(self, model, index):\n",
    "        self.cpu_layers = []\n",
    "        self.gpu_layers = []\n",
    "        self.index = index\n",
    "        self.flatten = -1\n",
    "        for name, child in model.named_children():\n",
    "            if name =='classifier' or isinstance(child, nn.Linear):\n",
    "                self.flatten = len(self.cpu_layers)\n",
    "            if (type(child) != torch.nn.modules.container.Sequential):\n",
    "                self.cpu_layers.append(child)\n",
    "            else:\n",
    "                for layer in child:\n",
    "                    self.cpu_layers.append(layer)\n",
    "        for layer in self.cpu_layers:\n",
    "            self.gpu_layers.append(copy.deepcopy(layer).to('cuda'))\n",
    "\n",
    "    def inference(self, output):\n",
    "        for i, idx in enumerate(self.index):\n",
    "            # cpu : 0\n",
    "            if i == self.flatten:\n",
    "                output = torch.flatten(output,1)\n",
    "            if idx == 0:\n",
    "                if output.device != torch.device('cpu'):\n",
    "                    output = self.cpu_layers[i](output.to('cpu'))\n",
    "                else:\n",
    "                    output = self.cpu_layers[i](output)\n",
    "            else:\n",
    "                if output.device != torch.device('cuda'):\n",
    "                    output = self.gpu_layers[i](output.to('cuda'))\n",
    "                else:\n",
    "                    output = self.gpu_layers[i](output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c406f7be-87f3-4f08-ac13-64e27c557673",
   "metadata": {},
   "outputs": [],
   "source": [
    "lala = LaLaRAND(model_vgg, [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39b2d1be-b26e-47bc-acca-1fd2c9514053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8187e+00, -7.7547e-01, -2.1688e+00, -1.5295e+00, -7.3729e-01,\n",
       "          8.5522e-01,  1.3405e+00,  5.5653e-01, -4.4879e-01, -2.1291e-02,\n",
       "         -2.2459e+00,  1.9332e-01, -8.8087e-02, -1.0642e+00, -1.9726e+00,\n",
       "          3.7075e-01, -2.4181e+00, -2.7813e+00,  1.6629e+00, -1.1991e+00,\n",
       "         -3.3440e+00, -1.2319e+00,  1.2567e+00,  2.0972e-01, -7.6727e-01,\n",
       "          3.0221e-01, -2.3348e+00,  1.1756e+00, -6.1393e-01, -3.1954e+00,\n",
       "         -2.4683e+00, -1.1208e+00, -2.8223e+00,  2.9893e-02,  7.6028e-01,\n",
       "         -2.8909e+00, -1.3162e+00, -1.3294e+00,  4.4734e-01, -3.0534e+00,\n",
       "          9.4533e-01, -1.3536e-01, -6.7826e-01, -1.4641e+00,  2.0726e+00,\n",
       "          1.2581e+00,  2.1228e+00, -1.2933e+00, -1.0587e+00, -3.4016e+00,\n",
       "         -7.1268e-01, -3.8806e+00,  1.8723e+00,  9.3228e-01,  6.0546e-01,\n",
       "         -5.7991e-01, -8.7487e-01,  7.7443e-01,  1.2497e+00, -4.8223e-01,\n",
       "          3.4410e+00,  6.5624e-01, -1.6145e+00, -2.9017e+00, -5.8698e-01,\n",
       "          3.4991e+00,  5.9425e-01,  2.1731e+00,  5.0186e-01,  1.0465e+00,\n",
       "          3.6949e+00,  3.5689e+00,  7.3513e-01,  2.6390e+00,  1.8195e+00,\n",
       "          4.4373e+00,  2.0716e+00,  5.2670e+00,  6.0672e+00,  5.8235e+00,\n",
       "         -3.5985e+00, -3.2844e+00, -2.1459e+00, -1.8572e+00, -4.6105e-01,\n",
       "          7.7199e-02, -2.8897e+00, -3.6034e-01,  1.5573e-01, -1.5856e+00,\n",
       "         -1.9734e+00, -4.3479e+00,  6.7652e-01, -3.1091e-01,  2.6953e-01,\n",
       "         -5.3386e+00, -8.6531e-01, -2.8236e+00, -4.1917e+00,  4.4088e-01,\n",
       "         -1.8113e+00, -4.5381e+00,  2.3287e+00, -5.6533e-01, -9.9041e-01,\n",
       "         -3.4019e+00,  7.9484e-01,  9.2056e-01, -2.1518e-02,  6.9905e-01,\n",
       "          1.4431e+00,  2.8225e+00,  1.3767e+00,  2.2166e+00,  4.1857e+00,\n",
       "         -5.9478e-01, -5.4251e-01, -1.0616e-01,  2.3916e+00,  1.1151e-01,\n",
       "          9.8569e-01, -7.1248e-01,  1.9275e-01,  1.6271e+00,  7.8765e-01,\n",
       "          1.3229e+00,  1.7915e+00,  3.0785e-01, -1.5085e+00, -3.2533e-02,\n",
       "          5.2212e-02, -2.6188e+00, -2.6098e-01,  3.3603e-01,  1.3495e-01,\n",
       "         -1.6313e+00, -4.6424e+00, -3.7210e+00,  1.4993e+00, -1.0964e+00,\n",
       "         -2.0789e+00, -1.3917e+00, -2.5720e+00, -2.3302e+00, -4.0555e-02,\n",
       "         -2.9814e+00, -2.5625e+00, -3.3285e+00, -2.0489e+00, -3.0381e+00,\n",
       "         -1.2493e+00,  8.5165e-01, -5.2865e+00, -1.7413e+00, -2.2956e-01,\n",
       "         -5.0155e-01, -1.0340e+00, -1.6228e+00, -1.8072e+00, -7.7574e-01,\n",
       "         -2.5980e+00,  6.3281e-01, -1.4816e-02, -1.1593e+00, -1.5571e+00,\n",
       "         -1.5187e+00, -1.7146e+00, -4.9077e+00,  1.3558e+00, -2.9843e+00,\n",
       "         -1.9062e+00,  1.9914e+00, -2.9472e+00,  2.6514e-01, -6.4933e-01,\n",
       "         -3.6041e+00, -3.3416e+00, -2.8719e+00,  3.1572e-01, -1.7673e+00,\n",
       "         -1.3739e+00, -2.3223e+00,  1.9240e+00, -1.8306e+00, -3.2517e-01,\n",
       "          6.5021e-01, -6.0778e-01,  2.7985e-01, -2.9610e+00, -4.8843e-01,\n",
       "         -3.4456e+00, -4.7460e-01,  3.6005e-01, -4.0387e-01, -2.9973e+00,\n",
       "          1.9987e-01, -8.2488e-01, -2.6496e+00, -1.7282e+00,  1.0486e+00,\n",
       "         -3.1112e+00,  1.5104e+00,  1.8888e+00,  1.5295e+00, -2.0762e-01,\n",
       "         -2.8443e+00, -4.0896e+00,  3.3832e-02, -8.1901e-01,  4.2099e-01,\n",
       "         -2.9426e+00,  5.5143e-02, -8.7601e-01, -1.1960e+00, -2.6535e+00,\n",
       "         -9.1491e-01, -3.0574e+00, -1.5499e+00, -1.9538e-01, -8.0463e-02,\n",
       "         -4.4556e+00, -2.3848e+00, -2.7002e+00,  1.5068e+00, -7.1223e-01,\n",
       "         -3.3210e-01, -1.3640e+00, -8.5472e-01, -2.5961e+00, -1.3467e+00,\n",
       "          4.9587e-01, -2.5704e-01, -7.5658e-01, -2.5884e+00,  1.8338e-01,\n",
       "          2.5194e-01, -3.7558e-01, -3.8303e-02, -1.6187e+00, -1.6384e+00,\n",
       "         -1.8757e+00, -1.6723e+00, -1.0996e+00, -2.1500e+00, -5.4611e+00,\n",
       "          1.1294e+00, -3.5926e+00, -2.1698e+00,  1.3758e-01, -9.8455e-01,\n",
       "          3.9730e-01, -1.4780e+00, -4.3644e+00, -1.7133e-01, -4.0622e-01,\n",
       "         -2.8085e+00, -2.1268e+00, -5.9322e-01,  3.0866e-01,  7.0402e-01,\n",
       "          2.0011e-01, -1.1620e+00, -3.6176e+00,  2.5911e+00, -1.4382e+00,\n",
       "         -2.1756e-02, -1.1970e+00, -2.3327e+00, -4.5456e+00, -3.4424e-01,\n",
       "          3.9769e-02, -9.3597e-01,  2.1464e+00,  9.3383e-01, -1.3659e+00,\n",
       "         -1.5262e+00, -3.8059e-01,  4.6923e-01, -1.5438e+00, -9.2670e-01,\n",
       "          5.6522e-01,  1.5784e+00,  1.2519e+00,  5.9920e-01,  1.4821e+00,\n",
       "          7.1454e-01, -4.4200e-01, -2.0403e-01, -1.5965e+00, -3.3217e+00,\n",
       "         -2.2602e+00, -1.1087e+00, -1.8365e+00,  1.0620e+00, -8.1567e-01,\n",
       "         -1.4541e+00, -4.7061e-01, -3.0823e+00, -6.9707e-01,  6.4263e-01,\n",
       "          3.8881e-01,  2.2014e+00,  7.1856e-01,  1.8639e+00, -1.0119e-01,\n",
       "          1.6589e+00,  2.2642e+00,  1.0075e+00,  1.6618e+00,  6.4284e-01,\n",
       "          5.5826e+00,  1.6302e+00,  2.2410e+00,  4.0139e+00,  4.8197e+00,\n",
       "          1.3829e+00,  1.4041e+00,  8.5104e-01,  3.9211e+00,  2.0207e+00,\n",
       "          1.7286e-01, -2.6168e+00, -2.1804e+00, -1.3535e+00, -2.6328e+00,\n",
       "         -2.2048e+00, -3.4063e+00,  4.1343e+00,  3.6854e+00, -4.4650e-01,\n",
       "          6.9928e-01, -1.0204e+00,  4.8285e-01, -1.1441e-01,  1.3078e+00,\n",
       "         -2.4106e+00, -2.8639e+00, -1.3569e+00, -5.4130e-01, -1.8977e+00,\n",
       "         -9.0508e-01, -5.3980e-01, -6.2730e-01, -2.2049e+00, -3.8849e+00,\n",
       "         -1.7516e+00, -2.6152e+00, -1.9760e+00, -2.0582e+00, -3.0633e+00,\n",
       "         -1.5371e+00, -1.5885e+00, -2.1485e+00,  6.9143e-01, -1.6424e+00,\n",
       "         -2.3229e+00, -3.0263e-01, -3.2073e+00, -8.8534e-02,  1.5301e+00,\n",
       "         -2.3596e+00,  1.8173e+00,  8.7471e-01,  1.0782e+00, -2.0833e+00,\n",
       "         -1.3398e+00, -2.2557e+00, -1.6815e+00, -1.8014e+00, -3.8327e+00,\n",
       "         -2.8927e+00, -2.1250e+00, -1.2413e-01, -2.8354e-01, -1.3399e+00,\n",
       "         -3.7973e+00, -3.1388e+00, -1.5627e+00, -1.9636e+00, -3.2678e+00,\n",
       "         -1.6798e+00, -4.8943e-01, -3.8080e-01, -6.0782e-01, -5.1827e+00,\n",
       "         -1.4804e+00, -2.0275e+00, -1.9045e+00, -2.8888e+00, -1.3529e+00,\n",
       "          2.0817e-01,  1.3796e+00, -3.0557e+00, -1.5764e+00, -3.3411e+00,\n",
       "         -1.8552e-01,  8.2043e-01, -4.2144e-02,  1.1008e+00,  8.0177e-01,\n",
       "         -2.8443e+00,  5.9332e-01,  1.1792e+00, -1.4372e+00, -1.8183e+00,\n",
       "          2.1175e+00,  1.2340e-01, -6.7172e-01, -2.1271e+00,  3.4764e+00,\n",
       "          6.1527e-01,  1.5328e+00,  2.6567e+00,  8.2272e-02,  1.2725e+00,\n",
       "         -2.3833e+00, -1.2232e+00,  3.6448e-02,  3.7224e+00,  4.7026e+00,\n",
       "          2.1135e+00,  2.7626e+00,  1.2880e+00, -9.2361e-01, -7.6111e-01,\n",
       "          1.4655e+00,  2.1487e+00,  1.0370e+00,  1.5212e+00,  1.5334e+00,\n",
       "          8.3939e-01, -2.0687e+00,  1.6741e+00, -2.0226e+00,  2.2386e+00,\n",
       "         -4.4893e-01, -6.5539e-01, -4.3302e-01, -1.0254e+00, -1.7998e+00,\n",
       "          2.2708e+00,  2.5007e+00,  6.9252e-01,  1.7734e+00,  1.7260e+00,\n",
       "         -7.0728e-01,  5.4917e+00, -6.5624e-01, -6.7390e-02,  1.6128e-02,\n",
       "         -1.9457e+00,  3.7401e+00,  1.5712e+00, -6.7325e-01, -1.5038e+00,\n",
       "          3.1159e+00,  2.8194e+00, -2.7727e-01,  3.6394e+00, -1.4152e+00,\n",
       "          2.4288e-01,  9.0988e-02,  4.1528e+00,  6.1743e-02,  2.1455e+00,\n",
       "         -1.4548e+00, -3.2769e+00, -2.0992e+00,  2.0989e+00, -1.5300e+00,\n",
       "          1.1807e+00, -5.8068e-01, -5.7043e-01,  1.5766e+00,  2.1310e+00,\n",
       "          8.0110e-01, -4.3629e+00,  3.9036e-01,  2.9501e+00, -1.0053e+00,\n",
       "          2.1464e+00,  1.0388e+00,  5.4961e-01, -9.9869e-01,  1.0009e-01,\n",
       "          7.4245e-01, -4.7573e-01,  1.0423e+00,  3.4125e+00,  4.8794e+00,\n",
       "          2.7506e+00, -1.0176e+00,  3.2863e+00, -1.1920e+00,  5.8747e-01,\n",
       "         -3.3270e+00,  1.3685e+00,  2.1985e+00,  2.6369e+00, -3.2465e-01,\n",
       "          1.3237e-01,  6.9236e-01, -6.2127e-01, -7.5361e-02, -9.9422e-02,\n",
       "         -1.0900e+00,  2.1605e+00,  2.8927e+00,  7.7810e-01, -2.8376e+00,\n",
       "         -3.0482e+00, -1.2945e+00,  2.0129e+00,  3.1900e-01,  7.6778e-01,\n",
       "          8.5233e-01, -2.2444e+00,  8.5388e-01, -9.9183e-01,  1.6444e+00,\n",
       "         -2.1321e+00, -1.3542e+00, -6.8927e-01,  1.6994e+00, -1.7363e+00,\n",
       "          7.2420e-01, -9.2566e-01, -1.3644e+00, -4.5170e-01, -1.3978e+00,\n",
       "          2.4000e+00,  1.3744e+00,  2.5866e-01,  4.0184e+00, -3.3679e-01,\n",
       "         -4.3595e+00,  1.2216e-01, -1.0472e+00,  2.2007e+00,  7.0062e+00,\n",
       "         -8.3715e-01, -2.9440e-01,  2.5058e+00,  1.1657e+00, -1.4955e+00,\n",
       "          2.3855e+00, -1.1780e-01, -3.9076e+00, -1.0135e+00,  5.7280e+00,\n",
       "         -3.7298e+00,  2.2446e+00,  1.8892e+00,  4.8967e+00, -1.7141e+00,\n",
       "         -7.6445e-02,  4.7711e+00,  2.9284e+00,  1.7861e-01,  2.9765e+00,\n",
       "         -1.3196e+00, -2.9844e-01,  3.9246e+00,  4.3149e+00, -3.3848e+00,\n",
       "          1.0573e+00,  5.0300e-01,  4.2181e-01,  6.3128e-01, -1.9667e+00,\n",
       "          5.8694e-01, -7.0329e-01,  1.7600e+00, -9.0750e-01,  7.3694e-01,\n",
       "         -5.9787e-01, -1.5106e+00, -6.5279e-01, -2.0386e+00,  3.1428e-01,\n",
       "          7.8545e-01,  7.4469e-01, -1.6331e+00, -5.1623e-01,  3.1504e+00,\n",
       "          9.7760e-02, -2.6370e+00,  2.9662e+00,  2.4387e+00,  8.1403e-01,\n",
       "         -3.5277e+00,  2.1542e+00,  3.9421e-01, -4.7258e-01, -3.9088e-01,\n",
       "          8.6329e-02,  2.0127e+00,  2.6082e+00, -1.4199e+00,  3.1642e+00,\n",
       "          5.7241e+00, -9.3416e-01, -7.2585e-01, -1.1899e+00, -7.4449e-01,\n",
       "          6.6698e-01,  5.5532e-01, -2.1199e+00,  3.7073e+00, -1.2362e+00,\n",
       "          1.1235e+00,  3.3858e+00, -6.3937e-01,  8.5841e-01, -1.4356e-01,\n",
       "         -2.6061e-01,  3.7776e+00, -2.1800e+00,  3.3809e+00,  4.0387e+00,\n",
       "          3.4417e+00,  2.1719e+00,  2.4294e+00,  2.7709e+00,  6.9594e-01,\n",
       "         -1.5245e+00,  1.8873e+00,  4.5256e-01, -9.1694e-01,  2.5480e+00,\n",
       "          1.4217e+00, -1.1422e+00,  3.5551e+00,  1.8086e+00, -3.3058e+00,\n",
       "          1.4152e+00,  2.9402e+00,  2.1042e+00, -1.2585e+00, -1.1753e+00,\n",
       "          4.3503e+00, -4.3163e-01, -1.7271e+00, -9.2809e-01,  5.8940e+00,\n",
       "         -1.8951e+00,  4.0543e+00,  1.0866e+00, -1.2855e+00, -2.3057e-01,\n",
       "          3.0740e+00,  1.0928e+00, -1.3978e+00, -1.0584e+00, -9.9315e-01,\n",
       "          1.7581e+00,  4.3012e-01,  1.6888e+00,  2.3225e+00, -1.4112e+00,\n",
       "         -1.0292e+00, -2.6355e-01,  2.2740e+00, -7.5998e-01,  1.2103e+00,\n",
       "          1.1802e+00, -2.6428e-02,  5.4450e-01, -8.2747e-01,  7.7363e-01,\n",
       "          2.0509e-01,  1.2623e+00, -3.1723e+00,  1.5721e+00,  3.1823e+00,\n",
       "         -8.8607e-01, -1.7799e+00,  5.5908e+00, -2.2504e+00,  2.1603e+00,\n",
       "         -7.2134e-01,  2.7217e+00,  3.4522e+00, -1.1153e+00, -2.4210e+00,\n",
       "         -1.0108e+00, -1.7554e+00, -1.7368e+00,  1.1829e-01, -2.3192e+00,\n",
       "         -2.5140e+00, -3.3390e+00,  2.5686e+00,  2.9318e-01,  1.3228e-01,\n",
       "          4.2117e+00,  4.3755e+00, -1.8752e+00, -1.4140e+00, -1.4921e+00,\n",
       "          5.1384e+00,  1.5726e+00, -4.2009e-01,  8.4100e-01,  5.2230e+00,\n",
       "         -1.9513e+00,  4.3318e-01,  2.1231e+00, -1.1281e+00,  2.8741e+00,\n",
       "          9.7998e-01,  4.9994e-01, -5.7842e-01, -1.3950e+00,  6.7354e-01,\n",
       "         -2.6520e+00,  2.1656e+00, -3.5426e+00,  6.9792e-01, -8.1762e-01,\n",
       "          9.5255e-01,  4.4139e+00,  1.5127e+00,  5.9090e-01, -3.0964e+00,\n",
       "          3.4490e-01, -1.3668e+00,  2.9251e+00,  8.6117e-01, -3.3231e+00,\n",
       "          8.5767e-01,  2.9871e+00, -8.5658e-01,  4.8254e+00, -1.7021e+00,\n",
       "          4.1038e+00, -3.0380e-01,  2.0887e+00,  1.6811e+00, -6.8667e+00,\n",
       "          6.9638e-01,  4.5527e+00,  6.9762e-01, -2.0054e-01,  3.1960e-01,\n",
       "         -3.4018e-01,  1.1808e+00,  1.1240e+00,  2.2231e+00,  3.6917e+00,\n",
       "          6.0779e-01,  5.8293e-01,  4.3689e+00,  2.7073e+00,  1.8767e+00,\n",
       "          9.1982e-02,  4.3620e-01, -1.3657e+00,  2.1148e+00,  8.5129e-02,\n",
       "          1.3967e+00,  9.1268e-01, -3.0695e+00,  2.7977e+00,  3.1493e+00,\n",
       "          1.4978e+00, -1.5106e+00,  3.0649e+00,  7.8594e-01,  3.5433e+00,\n",
       "          7.6167e-01,  2.3897e+00,  6.6828e+00,  4.1387e-01,  1.0922e+00,\n",
       "          2.8524e-01,  8.6027e-01,  2.1124e+00, -1.4251e-02, -1.1707e+00,\n",
       "         -9.2573e-01, -4.6540e-01,  1.4512e+00,  5.1983e+00,  5.0724e+00,\n",
       "         -7.2225e-01,  4.0921e-01, -7.1765e-01,  3.3587e-01,  1.3707e+00,\n",
       "         -3.1219e-01,  4.2052e+00,  5.0694e+00, -2.5266e-01,  3.3992e+00,\n",
       "          2.9388e+00,  1.7491e-01, -1.0330e+00,  9.9653e-01,  2.6478e+00,\n",
       "         -2.8581e+00, -5.3394e-01, -1.8034e+00, -9.7351e-01,  1.2847e+00,\n",
       "         -2.7709e-01,  7.4993e-01,  2.1262e+00,  3.0239e-01, -9.4251e-01,\n",
       "         -2.5170e+00,  2.0718e+00,  1.1710e-01,  2.3597e+00, -1.2490e+00,\n",
       "          2.7984e+00,  3.3138e+00, -2.9845e+00,  4.3045e+00, -1.2131e-01,\n",
       "         -2.4073e+00, -1.3909e+00, -3.0935e+00, -2.6742e-01,  2.3503e+00,\n",
       "         -1.3801e+00,  2.1502e+00, -1.1201e+00,  3.8399e+00, -2.9141e-01,\n",
       "         -6.3382e-01, -4.9107e-01, -2.1013e+00, -7.9415e-01,  7.9218e-01,\n",
       "          3.9311e+00, -2.3993e-01,  1.2896e+00,  6.3960e-02,  7.0889e-01,\n",
       "          3.9149e+00,  1.4650e+00, -5.7272e-01,  9.0388e-01,  4.7409e+00,\n",
       "          5.0382e+00,  1.4880e+00, -2.1972e+00,  7.5709e-01, -1.6184e+00,\n",
       "         -1.1077e+00,  1.7847e+00,  3.0611e+00,  1.4243e+00,  6.4834e-01,\n",
       "          3.0781e+00, -4.7368e+00, -2.8049e-01,  2.9990e+00,  9.9017e-01,\n",
       "         -1.9028e+00, -2.6688e-02,  6.5823e-01, -1.1709e+00, -1.9917e+00,\n",
       "         -4.0744e+00, -8.7755e-01,  6.9407e-01,  1.3444e+00,  2.7191e-02,\n",
       "          1.8930e+00,  7.5824e-01,  3.7613e+00,  8.2838e-02, -2.8562e+00,\n",
       "          1.0019e-01, -8.0722e-01,  7.4816e-01, -1.8227e+00,  4.6120e+00,\n",
       "          3.6173e+00, -9.5667e-01,  3.7675e+00,  7.4388e-01,  1.7737e+00,\n",
       "          3.3008e+00,  1.2970e-01, -3.0859e+00, -1.3377e+00,  1.0805e+00,\n",
       "         -9.0486e-02,  1.5964e-01,  6.1393e+00,  4.0484e+00,  1.9712e+00,\n",
       "         -1.6289e+00,  4.3447e-01,  4.9070e-02,  1.7215e+00, -2.6190e-03,\n",
       "         -1.1677e-01, -2.5790e+00,  1.7005e+00,  5.5227e-01,  7.3815e+00,\n",
       "          2.3321e+00, -6.0844e-01,  7.8756e-01,  1.4680e+00, -5.6674e-01,\n",
       "          2.5132e+00,  4.9640e+00,  9.6665e-02, -1.4113e+00, -2.0353e+00,\n",
       "         -1.3775e+00,  1.9058e-01,  3.7260e-02,  2.2794e+00,  2.5621e+00,\n",
       "          2.8769e+00,  3.1695e+00,  3.7308e-03, -3.7224e+00, -3.5746e+00,\n",
       "         -2.3442e+00, -4.9764e+00, -2.9997e+00, -1.5101e+00,  8.7167e-01,\n",
       "         -9.1284e-01, -2.1772e+00, -6.1142e-02, -2.1155e+00, -2.0386e+00,\n",
       "         -2.6624e+00, -4.0908e+00, -5.7254e-01, -2.9686e+00, -1.4400e+00,\n",
       "         -1.3515e+00, -3.3781e+00, -2.0887e+00, -3.3393e+00, -1.3389e+00,\n",
       "         -2.5668e+00, -2.0181e+00, -1.0382e+00,  4.7694e-01, -1.5257e-01,\n",
       "          3.4134e+00,  2.9249e+00, -1.5685e-01, -2.8715e-01,  2.1012e-01,\n",
       "         -1.4216e+00, -4.4166e+00,  1.8245e+00,  1.0061e+00, -2.3347e+00,\n",
       "         -1.3167e+00, -1.2388e+00, -1.8560e+00,  7.6219e-01, -2.0667e+00,\n",
       "         -3.0245e+00,  1.4644e+00,  1.0348e+00,  1.3778e+00, -3.7677e-01,\n",
       "         -1.7828e+00,  3.6568e+00,  1.4589e+00,  7.5153e-01, -1.9521e+00,\n",
       "          1.0842e+00, -1.4886e+00,  3.7260e+00,  2.2369e+00, -1.2574e+00,\n",
       "         -3.9425e-01, -1.3382e+00, -9.2974e-02, -1.7508e+00, -8.6034e-02,\n",
       "         -1.9105e-01, -3.9914e+00,  2.1232e+00,  1.0700e+00,  2.2695e-01,\n",
       "          1.1643e+00, -4.8040e-01, -2.1429e+00, -4.7498e+00, -2.2983e+00,\n",
       "         -1.9902e+00, -1.1560e+00, -6.1018e-01,  5.9136e-01,  2.8682e+00]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "rinput = torch.randn((1, 3,224,224))\n",
    "lala.inference(rinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "179456a1-83a3-46dc-8d8b-1885d0d599fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8181e+00, -7.7377e-01, -2.1679e+00, -1.5287e+00, -7.3630e-01,\n",
       "          8.5632e-01,  1.3410e+00,  5.5622e-01, -4.4924e-01, -2.0753e-02,\n",
       "         -2.2451e+00,  1.9450e-01, -8.6689e-02, -1.0630e+00, -1.9707e+00,\n",
       "          3.7135e-01, -2.4160e+00, -2.7799e+00,  1.6631e+00, -1.1976e+00,\n",
       "         -3.3429e+00, -1.2300e+00,  1.2576e+00,  2.1010e-01, -7.6572e-01,\n",
       "          3.0103e-01, -2.3354e+00,  1.1750e+00, -6.1483e-01, -3.1952e+00,\n",
       "         -2.4682e+00, -1.1218e+00, -2.8238e+00,  2.9546e-02,  7.6005e-01,\n",
       "         -2.8901e+00, -1.3152e+00, -1.3294e+00,  4.4723e-01, -3.0542e+00,\n",
       "          9.4510e-01, -1.3615e-01, -6.7902e-01, -1.4633e+00,  2.0713e+00,\n",
       "          1.2558e+00,  2.1221e+00, -1.2942e+00, -1.0598e+00, -3.4017e+00,\n",
       "         -7.1295e-01, -3.8807e+00,  1.8711e+00,  9.3130e-01,  6.0394e-01,\n",
       "         -5.7933e-01, -8.7617e-01,  7.7386e-01,  1.2507e+00, -4.8177e-01,\n",
       "          3.4398e+00,  6.5526e-01, -1.6157e+00, -2.9014e+00, -5.8698e-01,\n",
       "          3.4992e+00,  5.9270e-01,  2.1713e+00,  5.0012e-01,  1.0453e+00,\n",
       "          3.6929e+00,  3.5670e+00,  7.3471e-01,  2.6381e+00,  1.8185e+00,\n",
       "          4.4354e+00,  2.0706e+00,  5.2658e+00,  6.0647e+00,  5.8212e+00,\n",
       "         -3.5981e+00, -3.2839e+00, -2.1461e+00, -1.8578e+00, -4.5945e-01,\n",
       "          7.7580e-02, -2.8894e+00, -3.6004e-01,  1.5701e-01, -1.5841e+00,\n",
       "         -1.9715e+00, -4.3461e+00,  6.7697e-01, -3.1133e-01,  2.7086e-01,\n",
       "         -5.3366e+00, -8.6425e-01, -2.8221e+00, -4.1905e+00,  4.4081e-01,\n",
       "         -1.8106e+00, -4.5376e+00,  2.3273e+00, -5.6383e-01, -9.9103e-01,\n",
       "         -3.4004e+00,  7.9331e-01,  9.2333e-01, -1.9381e-02,  7.0067e-01,\n",
       "          1.4443e+00,  2.8231e+00,  1.3772e+00,  2.2178e+00,  4.1857e+00,\n",
       "         -5.9280e-01, -5.4089e-01, -1.0576e-01,  2.3911e+00,  1.1094e-01,\n",
       "          9.8457e-01, -7.1276e-01,  1.9221e-01,  1.6265e+00,  7.8677e-01,\n",
       "          1.3227e+00,  1.7907e+00,  3.0831e-01, -1.5088e+00, -3.1077e-02,\n",
       "          5.3393e-02, -2.6172e+00, -2.5895e-01,  3.3692e-01,  1.3542e-01,\n",
       "         -1.6300e+00, -4.6419e+00, -3.7204e+00,  1.4989e+00, -1.0964e+00,\n",
       "         -2.0785e+00, -1.3914e+00, -2.5715e+00, -2.3300e+00, -3.9678e-02,\n",
       "         -2.9804e+00, -2.5627e+00, -3.3267e+00, -2.0484e+00, -3.0368e+00,\n",
       "         -1.2475e+00,  8.5080e-01, -5.2861e+00, -1.7412e+00, -2.2987e-01,\n",
       "         -5.0123e-01, -1.0342e+00, -1.6230e+00, -1.8082e+00, -7.7578e-01,\n",
       "         -2.5968e+00,  6.3251e-01, -1.5390e-02, -1.1597e+00, -1.5578e+00,\n",
       "         -1.5196e+00, -1.7150e+00, -4.9071e+00,  1.3551e+00, -2.9841e+00,\n",
       "         -1.9057e+00,  1.9907e+00, -2.9475e+00,  2.6449e-01, -6.4995e-01,\n",
       "         -3.6039e+00, -3.3417e+00, -2.8713e+00,  3.1567e-01, -1.7679e+00,\n",
       "         -1.3740e+00, -2.3217e+00,  1.9235e+00, -1.8306e+00, -3.2541e-01,\n",
       "          6.4915e-01, -6.0851e-01,  2.7929e-01, -2.9606e+00, -4.8843e-01,\n",
       "         -3.4452e+00, -4.7421e-01,  3.5922e-01, -4.0446e-01, -2.9969e+00,\n",
       "          1.9934e-01, -8.2472e-01, -2.6493e+00, -1.7275e+00,  1.0481e+00,\n",
       "         -3.1108e+00,  1.5099e+00,  1.8889e+00,  1.5296e+00, -2.0770e-01,\n",
       "         -2.8438e+00, -4.0892e+00,  3.4220e-02, -8.1916e-01,  4.2113e-01,\n",
       "         -2.9423e+00,  5.4344e-02, -8.7539e-01, -1.1954e+00, -2.6534e+00,\n",
       "         -9.1521e-01, -3.0573e+00, -1.5495e+00, -1.9530e-01, -7.9722e-02,\n",
       "         -4.4545e+00, -2.3836e+00, -2.6997e+00,  1.5061e+00, -7.1174e-01,\n",
       "         -3.3163e-01, -1.3636e+00, -8.5493e-01, -2.5960e+00, -1.3468e+00,\n",
       "          4.9467e-01, -2.5792e-01, -7.5627e-01, -2.5882e+00,  1.8271e-01,\n",
       "          2.5180e-01, -3.7702e-01, -3.9177e-02, -1.6195e+00, -1.6386e+00,\n",
       "         -1.8760e+00, -1.6722e+00, -1.0995e+00, -2.1501e+00, -5.4608e+00,\n",
       "          1.1291e+00, -3.5924e+00, -2.1696e+00,  1.3681e-01, -9.8468e-01,\n",
       "          3.9726e-01, -1.4778e+00, -4.3641e+00, -1.7201e-01, -4.0642e-01,\n",
       "         -2.8074e+00, -2.1266e+00, -5.9352e-01,  3.0753e-01,  7.0302e-01,\n",
       "          1.9986e-01, -1.1626e+00, -3.6182e+00,  2.5904e+00, -1.4387e+00,\n",
       "         -2.2709e-02, -1.1975e+00, -2.3326e+00, -4.5456e+00, -3.4429e-01,\n",
       "          3.9373e-02, -9.3601e-01,  2.1450e+00,  9.3196e-01, -1.3664e+00,\n",
       "         -1.5268e+00, -3.8147e-01,  4.6885e-01, -1.5449e+00, -9.2698e-01,\n",
       "          5.6484e-01,  1.5784e+00,  1.2516e+00,  5.9875e-01,  1.4831e+00,\n",
       "          7.1444e-01, -4.4043e-01, -2.0452e-01, -1.5959e+00, -3.3210e+00,\n",
       "         -2.2594e+00, -1.1094e+00, -1.8361e+00,  1.0615e+00, -8.1483e-01,\n",
       "         -1.4543e+00, -4.6958e-01, -3.0825e+00, -6.9708e-01,  6.4280e-01,\n",
       "          3.8748e-01,  2.2002e+00,  7.1711e-01,  1.8626e+00, -1.0203e-01,\n",
       "          1.6569e+00,  2.2637e+00,  1.0061e+00,  1.6615e+00,  6.4329e-01,\n",
       "          5.5816e+00,  1.6284e+00,  2.2388e+00,  4.0119e+00,  4.8184e+00,\n",
       "          1.3820e+00,  1.4042e+00,  8.5051e-01,  3.9197e+00,  2.0195e+00,\n",
       "          1.7139e-01, -2.6168e+00, -2.1797e+00, -1.3524e+00, -2.6319e+00,\n",
       "         -2.2043e+00, -3.4056e+00,  4.1341e+00,  3.6851e+00, -4.4575e-01,\n",
       "          6.9831e-01, -1.0206e+00,  4.8230e-01, -1.1511e-01,  1.3084e+00,\n",
       "         -2.4098e+00, -2.8636e+00, -1.3559e+00, -5.4107e-01, -1.8969e+00,\n",
       "         -9.0551e-01, -5.4079e-01, -6.2833e-01, -2.2058e+00, -3.8851e+00,\n",
       "         -1.7505e+00, -2.6150e+00, -1.9760e+00, -2.0587e+00, -3.0635e+00,\n",
       "         -1.5374e+00, -1.5894e+00, -2.1482e+00,  6.9074e-01, -1.6421e+00,\n",
       "         -2.3218e+00, -3.0253e-01, -3.2068e+00, -8.8446e-02,  1.5292e+00,\n",
       "         -2.3575e+00,  1.8168e+00,  8.7389e-01,  1.0756e+00, -2.0820e+00,\n",
       "         -1.3383e+00, -2.2544e+00, -1.6814e+00, -1.7995e+00, -3.8312e+00,\n",
       "         -2.8915e+00, -2.1240e+00, -1.2401e-01, -2.8256e-01, -1.3383e+00,\n",
       "         -3.7955e+00, -3.1375e+00, -1.5617e+00, -1.9627e+00, -3.2654e+00,\n",
       "         -1.6783e+00, -4.8842e-01, -3.7985e-01, -6.0745e-01, -5.1813e+00,\n",
       "         -1.4801e+00, -2.0273e+00, -1.9036e+00, -2.8883e+00, -1.3528e+00,\n",
       "          2.0975e-01,  1.3802e+00, -3.0539e+00, -1.5728e+00, -3.3395e+00,\n",
       "         -1.8573e-01,  8.2204e-01, -4.1312e-02,  1.1008e+00,  8.0114e-01,\n",
       "         -2.8437e+00,  5.9236e-01,  1.1797e+00, -1.4362e+00, -1.8184e+00,\n",
       "          2.1167e+00,  1.2395e-01, -6.7227e-01, -2.1273e+00,  3.4773e+00,\n",
       "          6.1521e-01,  1.5336e+00,  2.6561e+00,  8.1145e-02,  1.2731e+00,\n",
       "         -2.3830e+00, -1.2231e+00,  3.7027e-02,  3.7205e+00,  4.7010e+00,\n",
       "          2.1130e+00,  2.7619e+00,  1.2870e+00, -9.2484e-01, -7.6135e-01,\n",
       "          1.4663e+00,  2.1489e+00,  1.0378e+00,  1.5208e+00,  1.5314e+00,\n",
       "          8.3946e-01, -2.0689e+00,  1.6738e+00, -2.0217e+00,  2.2376e+00,\n",
       "         -4.4970e-01, -6.5567e-01, -4.3218e-01, -1.0238e+00, -1.7997e+00,\n",
       "          2.2715e+00,  2.5022e+00,  6.9402e-01,  1.7731e+00,  1.7261e+00,\n",
       "         -7.0666e-01,  5.4911e+00, -6.5629e-01, -6.6523e-02,  1.6877e-02,\n",
       "         -1.9472e+00,  3.7390e+00,  1.5718e+00, -6.7297e-01, -1.5030e+00,\n",
       "          3.1156e+00,  2.8185e+00, -2.7689e-01,  3.6402e+00, -1.4145e+00,\n",
       "          2.4322e-01,  9.1487e-02,  4.1526e+00,  6.2238e-02,  2.1454e+00,\n",
       "         -1.4547e+00, -3.2778e+00, -2.0995e+00,  2.0991e+00, -1.5303e+00,\n",
       "          1.1797e+00, -5.8051e-01, -5.6973e-01,  1.5764e+00,  2.1309e+00,\n",
       "          8.0110e-01, -4.3606e+00,  3.9001e-01,  2.9489e+00, -1.0064e+00,\n",
       "          2.1465e+00,  1.0386e+00,  5.4915e-01, -9.9752e-01,  1.0022e-01,\n",
       "          7.4203e-01, -4.7438e-01,  1.0408e+00,  3.4128e+00,  4.8795e+00,\n",
       "          2.7514e+00, -1.0174e+00,  3.2856e+00, -1.1908e+00,  5.8816e-01,\n",
       "         -3.3260e+00,  1.3689e+00,  2.1991e+00,  2.6368e+00, -3.2556e-01,\n",
       "          1.3189e-01,  6.9298e-01, -6.2053e-01, -7.4754e-02, -9.9616e-02,\n",
       "         -1.0894e+00,  2.1606e+00,  2.8928e+00,  7.7761e-01, -2.8365e+00,\n",
       "         -3.0476e+00, -1.2953e+00,  2.0126e+00,  3.1928e-01,  7.6809e-01,\n",
       "          8.5120e-01, -2.2439e+00,  8.5389e-01, -9.9188e-01,  1.6439e+00,\n",
       "         -2.1327e+00, -1.3536e+00, -6.9000e-01,  1.6987e+00, -1.7353e+00,\n",
       "          7.2247e-01, -9.2572e-01, -1.3639e+00, -4.5161e-01, -1.3977e+00,\n",
       "          2.3996e+00,  1.3734e+00,  2.5786e-01,  4.0179e+00, -3.3710e-01,\n",
       "         -4.3590e+00,  1.2231e-01, -1.0477e+00,  2.2016e+00,  7.0054e+00,\n",
       "         -8.3596e-01, -2.9448e-01,  2.5044e+00,  1.1644e+00, -1.4964e+00,\n",
       "          2.3852e+00, -1.1772e-01, -3.9065e+00, -1.0135e+00,  5.7271e+00,\n",
       "         -3.7294e+00,  2.2447e+00,  1.8896e+00,  4.8963e+00, -1.7135e+00,\n",
       "         -7.5700e-02,  4.7693e+00,  2.9284e+00,  1.7782e-01,  2.9755e+00,\n",
       "         -1.3192e+00, -2.9860e-01,  3.9264e+00,  4.3123e+00, -3.3854e+00,\n",
       "          1.0589e+00,  5.0339e-01,  4.2160e-01,  6.3174e-01, -1.9664e+00,\n",
       "          5.8705e-01, -7.0339e-01,  1.7605e+00, -9.0853e-01,  7.3661e-01,\n",
       "         -5.9776e-01, -1.5100e+00, -6.5214e-01, -2.0376e+00,  3.1375e-01,\n",
       "          7.8622e-01,  7.4496e-01, -1.6335e+00, -5.1677e-01,  3.1497e+00,\n",
       "          9.8602e-02, -2.6364e+00,  2.9650e+00,  2.4379e+00,  8.1352e-01,\n",
       "         -3.5280e+00,  2.1528e+00,  3.9499e-01, -4.7319e-01, -3.9074e-01,\n",
       "          8.6300e-02,  2.0119e+00,  2.6077e+00, -1.4203e+00,  3.1630e+00,\n",
       "          5.7235e+00, -9.3363e-01, -7.2513e-01, -1.1899e+00, -7.4462e-01,\n",
       "          6.6642e-01,  5.5490e-01, -2.1193e+00,  3.7069e+00, -1.2364e+00,\n",
       "          1.1234e+00,  3.3882e+00, -6.3895e-01,  8.5806e-01, -1.4263e-01,\n",
       "         -2.6038e-01,  3.7786e+00, -2.1791e+00,  3.3808e+00,  4.0383e+00,\n",
       "          3.4411e+00,  2.1709e+00,  2.4277e+00,  2.7700e+00,  6.9603e-01,\n",
       "         -1.5240e+00,  1.8855e+00,  4.5157e-01, -9.1608e-01,  2.5465e+00,\n",
       "          1.4205e+00, -1.1420e+00,  3.5549e+00,  1.8084e+00, -3.3058e+00,\n",
       "          1.4155e+00,  2.9402e+00,  2.1041e+00, -1.2578e+00, -1.1743e+00,\n",
       "          4.3493e+00, -4.3190e-01, -1.7266e+00, -9.2743e-01,  5.8927e+00,\n",
       "         -1.8928e+00,  4.0539e+00,  1.0868e+00, -1.2857e+00, -2.2965e-01,\n",
       "          3.0728e+00,  1.0921e+00, -1.3976e+00, -1.0590e+00, -9.9345e-01,\n",
       "          1.7584e+00,  4.2991e-01,  1.6885e+00,  2.3221e+00, -1.4105e+00,\n",
       "         -1.0293e+00, -2.6423e-01,  2.2730e+00, -7.5871e-01,  1.2107e+00,\n",
       "          1.1793e+00, -2.7574e-02,  5.4497e-01, -8.2630e-01,  7.7315e-01,\n",
       "          2.0487e-01,  1.2623e+00, -3.1716e+00,  1.5715e+00,  3.1810e+00,\n",
       "         -8.8665e-01, -1.7805e+00,  5.5902e+00, -2.2508e+00,  2.1603e+00,\n",
       "         -7.1969e-01,  2.7211e+00,  3.4531e+00, -1.1163e+00, -2.4203e+00,\n",
       "         -1.0106e+00, -1.7557e+00, -1.7365e+00,  1.1786e-01, -2.3184e+00,\n",
       "         -2.5136e+00, -3.3390e+00,  2.5677e+00,  2.9316e-01,  1.3300e-01,\n",
       "          4.2119e+00,  4.3760e+00, -1.8743e+00, -1.4127e+00, -1.4927e+00,\n",
       "          5.1349e+00,  1.5718e+00, -4.2041e-01,  8.4116e-01,  5.2223e+00,\n",
       "         -1.9509e+00,  4.3341e-01,  2.1227e+00, -1.1272e+00,  2.8725e+00,\n",
       "          9.7891e-01,  5.0065e-01, -5.7712e-01, -1.3958e+00,  6.7337e-01,\n",
       "         -2.6512e+00,  2.1663e+00, -3.5427e+00,  6.9778e-01, -8.1804e-01,\n",
       "          9.5230e-01,  4.4134e+00,  1.5120e+00,  5.9148e-01, -3.0952e+00,\n",
       "          3.4606e-01, -1.3671e+00,  2.9259e+00,  8.6229e-01, -3.3226e+00,\n",
       "          8.5731e-01,  2.9862e+00, -8.5798e-01,  4.8254e+00, -1.7023e+00,\n",
       "          4.1029e+00, -3.0372e-01,  2.0897e+00,  1.6818e+00, -6.8660e+00,\n",
       "          6.9544e-01,  4.5526e+00,  6.9615e-01, -2.0066e-01,  3.1935e-01,\n",
       "         -3.4084e-01,  1.1787e+00,  1.1232e+00,  2.2227e+00,  3.6917e+00,\n",
       "          6.0674e-01,  5.8169e-01,  4.3682e+00,  2.7057e+00,  1.8768e+00,\n",
       "          9.2228e-02,  4.3658e-01, -1.3654e+00,  2.1141e+00,  8.4368e-02,\n",
       "          1.3960e+00,  9.1154e-01, -3.0686e+00,  2.7969e+00,  3.1480e+00,\n",
       "          1.4961e+00, -1.5116e+00,  3.0635e+00,  7.8560e-01,  3.5419e+00,\n",
       "          7.6218e-01,  2.3893e+00,  6.6817e+00,  4.1462e-01,  1.0925e+00,\n",
       "          2.8649e-01,  8.5972e-01,  2.1122e+00, -1.5083e-02, -1.1699e+00,\n",
       "         -9.2552e-01, -4.6470e-01,  1.4509e+00,  5.1977e+00,  5.0708e+00,\n",
       "         -7.2329e-01,  4.0852e-01, -7.1658e-01,  3.3639e-01,  1.3701e+00,\n",
       "         -3.1188e-01,  4.2048e+00,  5.0685e+00, -2.5198e-01,  3.3991e+00,\n",
       "          2.9380e+00,  1.7430e-01, -1.0332e+00,  9.9610e-01,  2.6478e+00,\n",
       "         -2.8573e+00, -5.3231e-01, -1.8034e+00, -9.7361e-01,  1.2847e+00,\n",
       "         -2.7767e-01,  7.4954e-01,  2.1260e+00,  3.0144e-01, -9.4242e-01,\n",
       "         -2.5180e+00,  2.0709e+00,  1.1635e-01,  2.3585e+00, -1.2488e+00,\n",
       "          2.7980e+00,  3.3133e+00, -2.9850e+00,  4.3048e+00, -1.2015e-01,\n",
       "         -2.4062e+00, -1.3899e+00, -3.0934e+00, -2.6752e-01,  2.3502e+00,\n",
       "         -1.3800e+00,  2.1486e+00, -1.1203e+00,  3.8393e+00, -2.9090e-01,\n",
       "         -6.3453e-01, -4.9266e-01, -2.1007e+00, -7.9454e-01,  7.9183e-01,\n",
       "          3.9314e+00, -2.3910e-01,  1.2905e+00,  6.4322e-02,  7.0987e-01,\n",
       "          3.9149e+00,  1.4652e+00, -5.7143e-01,  9.0380e-01,  4.7400e+00,\n",
       "          5.0365e+00,  1.4875e+00, -2.1967e+00,  7.5642e-01, -1.6179e+00,\n",
       "         -1.1074e+00,  1.7838e+00,  3.0605e+00,  1.4249e+00,  6.4857e-01,\n",
       "          3.0778e+00, -4.7362e+00, -2.7965e-01,  2.9996e+00,  9.8832e-01,\n",
       "         -1.9018e+00, -2.8252e-02,  6.5854e-01, -1.1697e+00, -1.9920e+00,\n",
       "         -4.0727e+00, -8.7811e-01,  6.9293e-01,  1.3451e+00,  2.7189e-02,\n",
       "          1.8926e+00,  7.5822e-01,  3.7601e+00,  8.3869e-02, -2.8560e+00,\n",
       "          1.0018e-01, -8.0817e-01,  7.4752e-01, -1.8235e+00,  4.6121e+00,\n",
       "          3.6174e+00, -9.5605e-01,  3.7668e+00,  7.4492e-01,  1.7735e+00,\n",
       "          3.3004e+00,  1.3017e-01, -3.0847e+00, -1.3372e+00,  1.0814e+00,\n",
       "         -9.0801e-02,  1.5821e-01,  6.1389e+00,  4.0473e+00,  1.9715e+00,\n",
       "         -1.6294e+00,  4.3399e-01,  4.7205e-02,  1.7226e+00, -2.1191e-03,\n",
       "         -1.1670e-01, -2.5777e+00,  1.6995e+00,  5.5360e-01,  7.3807e+00,\n",
       "          2.3326e+00, -6.0845e-01,  7.8755e-01,  1.4670e+00, -5.6796e-01,\n",
       "          2.5127e+00,  4.9630e+00,  9.6425e-02, -1.4102e+00, -2.0351e+00,\n",
       "         -1.3771e+00,  1.9123e-01,  3.8380e-02,  2.2786e+00,  2.5623e+00,\n",
       "          2.8764e+00,  3.1703e+00,  3.8014e-03, -3.7225e+00, -3.5741e+00,\n",
       "         -2.3438e+00, -4.9760e+00, -2.9993e+00, -1.5105e+00,  8.7209e-01,\n",
       "         -9.1376e-01, -2.1767e+00, -6.1308e-02, -2.1152e+00, -2.0393e+00,\n",
       "         -2.6628e+00, -4.0901e+00, -5.7171e-01, -2.9682e+00, -1.4399e+00,\n",
       "         -1.3518e+00, -3.3780e+00, -2.0884e+00, -3.3386e+00, -1.3384e+00,\n",
       "         -2.5666e+00, -2.0178e+00, -1.0368e+00,  4.7659e-01, -1.5298e-01,\n",
       "          3.4136e+00,  2.9255e+00, -1.5589e-01, -2.8796e-01,  2.1045e-01,\n",
       "         -1.4203e+00, -4.4164e+00,  1.8236e+00,  1.0062e+00, -2.3355e+00,\n",
       "         -1.3166e+00, -1.2396e+00, -1.8567e+00,  7.6067e-01, -2.0677e+00,\n",
       "         -3.0246e+00,  1.4640e+00,  1.0346e+00,  1.3777e+00, -3.7634e-01,\n",
       "         -1.7821e+00,  3.6588e+00,  1.4592e+00,  7.5414e-01, -1.9501e+00,\n",
       "          1.0856e+00, -1.4880e+00,  3.7263e+00,  2.2376e+00, -1.2566e+00,\n",
       "         -3.9365e-01, -1.3378e+00, -9.3182e-02, -1.7486e+00, -8.4828e-02,\n",
       "         -1.9110e-01, -3.9908e+00,  2.1231e+00,  1.0700e+00,  2.2717e-01,\n",
       "          1.1639e+00, -4.7936e-01, -2.1417e+00, -4.7491e+00, -2.2982e+00,\n",
       "         -1.9900e+00, -1.1548e+00, -6.0925e-01,  5.9115e-01,  2.8664e+00]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "output = torch.randn((1,3,224,224))\n",
    "for i,layer in enumerate(layers):\n",
    "    if i==22:\n",
    "        output = torch.flatten(output,1)\n",
    "    output = layer(output)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abe14622-4664-4667-ac9b-507bf47b3d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "output = torch.randn((1,3,224,224))\n",
    "print(output.shape)\n",
    "output.to('cuda')\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73a46229-5ff8-4d08-9564-897b5d543f64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lala.cpu_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1ccd4be-a437-49c7-8840-ff1e6bd0fb42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lala.gpu_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecdb6488-c433-4a5f-bf51-58aa5c8c657d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in lala.cpu_layers[24].parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39e3f82a-4e65-4c3f-b224-4e3eddeaa4d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 3.0254e-02, -1.7533e-02, -3.6280e-02],\n",
      "          [ 1.2538e-02, -5.0638e-02, -4.7784e-02],\n",
      "          [-2.2680e-02, -6.1058e-02, -3.7668e-02]],\n",
      "\n",
      "         [[ 5.9600e-02,  5.1336e-02,  7.3689e-03],\n",
      "          [ 2.8290e-02, -2.9061e-02, -4.2954e-02],\n",
      "          [ 1.0819e-02, -5.1261e-02, -4.0023e-02]],\n",
      "\n",
      "         [[-4.3808e-03, -3.3098e-02, -3.5701e-02],\n",
      "          [-6.3519e-04, -4.7153e-02, -2.5235e-02],\n",
      "          [-9.8631e-03, -2.9551e-02, -1.8993e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.4464e-02,  3.2984e-02,  7.0170e-03],\n",
      "          [ 3.2555e-04, -3.4360e-02, -2.2914e-02],\n",
      "          [-5.4545e-03, -2.0913e-02, -2.2754e-02]],\n",
      "\n",
      "         [[ 9.7823e-03, -5.8558e-03, -5.1789e-02],\n",
      "          [ 1.0889e-02, -2.7220e-02, -1.7536e-02],\n",
      "          [ 6.8614e-03,  6.6181e-03, -2.0886e-02]],\n",
      "\n",
      "         [[ 1.8090e-02, -8.1787e-03, -1.5797e-02],\n",
      "          [ 7.9613e-03, -2.1601e-02, -1.4560e-02],\n",
      "          [ 1.3267e-02, -1.1497e-02, -4.7489e-03]]],\n",
      "\n",
      "\n",
      "        [[[-8.3505e-03,  1.1460e-02,  3.1054e-02],\n",
      "          [-2.0902e-02,  1.0231e-02,  1.3582e-03],\n",
      "          [ 3.7972e-02,  6.7522e-02,  6.5534e-03]],\n",
      "\n",
      "         [[-4.7055e-02, -7.5419e-02, -2.9127e-03],\n",
      "          [-1.0046e-01, -8.6098e-02, -4.2206e-02],\n",
      "          [-1.1590e-02, -2.0100e-03,  3.5335e-03]],\n",
      "\n",
      "         [[ 3.7041e-02,  3.3340e-02,  2.6119e-02],\n",
      "          [-1.2132e-02, -4.7110e-02, -5.0812e-02],\n",
      "          [-1.9410e-02, -2.2056e-02,  1.2816e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3877e-02, -7.2855e-02, -1.9546e-02],\n",
      "          [-1.4112e-01, -1.6056e-01,  4.6272e-02],\n",
      "          [-4.4999e-02,  3.2510e-02,  1.6528e-01]],\n",
      "\n",
      "         [[-1.4184e-02, -2.7106e-02,  3.1081e-02],\n",
      "          [-9.6274e-03, -2.2353e-02,  1.2803e-02],\n",
      "          [-3.9670e-04, -2.7535e-03,  2.0714e-02]],\n",
      "\n",
      "         [[-3.4943e-02, -5.7016e-02, -1.4415e-02],\n",
      "          [-5.1795e-02, -3.9539e-02,  4.4942e-02],\n",
      "          [ 1.5049e-03,  6.8033e-03,  8.5095e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5952e-02,  1.1868e-01,  6.9009e-02],\n",
      "          [ 1.0953e-01,  2.2025e-02,  3.3651e-02],\n",
      "          [-4.9684e-03,  3.7668e-04, -3.1210e-03]],\n",
      "\n",
      "         [[-4.7280e-02,  5.1427e-02,  9.8919e-02],\n",
      "          [-9.0229e-02, -1.5083e-01, -2.9534e-02],\n",
      "          [-5.3147e-02, -1.2122e-01, -5.0498e-02]],\n",
      "\n",
      "         [[ 8.4518e-02,  6.9523e-02,  6.2139e-02],\n",
      "          [ 1.2506e-01,  1.2732e-01,  7.2160e-02],\n",
      "          [ 9.0297e-02,  6.0881e-02,  3.0049e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7505e-02,  4.5935e-02,  8.2298e-02],\n",
      "          [-8.2303e-02, -5.2299e-02,  5.3002e-03],\n",
      "          [ 2.5895e-02, -1.1137e-02,  6.5720e-02]],\n",
      "\n",
      "         [[-6.3648e-03, -4.4884e-03, -4.3971e-03],\n",
      "          [-1.6374e-02, -5.5705e-02, -1.8174e-02],\n",
      "          [ 8.2748e-03, -2.3522e-03,  2.6722e-02]],\n",
      "\n",
      "         [[ 8.0762e-02,  1.6764e-01,  1.7268e-01],\n",
      "          [-8.0824e-02, -4.3552e-02,  3.6035e-03],\n",
      "          [-1.2101e-01, -1.2685e-01, -1.2015e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.6950e-02,  6.1425e-02,  2.9428e-02],\n",
      "          [-2.0721e-02, -2.0610e-02, -9.0445e-03],\n",
      "          [-3.3807e-02, -2.3724e-02, -8.6056e-03]],\n",
      "\n",
      "         [[ 9.1089e-02, -1.0192e-01, -1.5200e-02],\n",
      "          [-1.0005e-02, -1.4195e-01, -3.7231e-02],\n",
      "          [-2.1861e-02, -1.5483e-02, -3.9845e-02]],\n",
      "\n",
      "         [[ 3.3416e-02,  7.2890e-02, -2.8328e-03],\n",
      "          [-1.9988e-02, -6.9784e-02, -5.0872e-02],\n",
      "          [-3.7640e-02, -3.2921e-02, -1.7241e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1865e-02,  5.4325e-02, -6.2780e-02],\n",
      "          [ 6.3609e-02,  6.2640e-02, -1.9746e-03],\n",
      "          [-1.5869e-03,  8.2071e-04, -7.7982e-03]],\n",
      "\n",
      "         [[ 4.0719e-02,  3.4562e-02, -8.3760e-03],\n",
      "          [ 2.9359e-02,  2.2786e-02, -1.1963e-02],\n",
      "          [-2.8316e-02, -2.3417e-02, -3.9147e-02]],\n",
      "\n",
      "         [[ 9.0389e-03,  1.0524e-02, -2.2764e-02],\n",
      "          [-2.7963e-02, -3.7551e-02, -3.6812e-02],\n",
      "          [-2.0950e-02, -2.4121e-02, -2.3312e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9799e-03,  2.2086e-01, -1.9825e-01],\n",
      "          [ 2.5548e-02, -5.2903e-02,  3.0777e-02],\n",
      "          [-4.7823e-02, -6.8841e-02,  1.7061e-01]],\n",
      "\n",
      "         [[-1.0685e-01, -2.1602e-01,  4.2354e-01],\n",
      "          [-1.1532e-01,  9.1418e-02, -2.7322e-02],\n",
      "          [ 1.3151e-01,  3.1803e-01, -3.4603e-01]],\n",
      "\n",
      "         [[ 3.1434e-02,  1.1428e-01, -1.4275e-01],\n",
      "          [ 1.4062e-02, -2.7443e-02,  1.2120e-02],\n",
      "          [-6.1721e-02, -6.1706e-02,  1.1395e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4014e-02, -6.6533e-02, -7.3589e-02],\n",
      "          [-1.1125e-02, -9.4889e-02, -1.2939e-01],\n",
      "          [ 5.1843e-02, -9.0470e-02, -4.7306e-02]],\n",
      "\n",
      "         [[-1.5773e-02,  2.2998e-02,  7.6813e-03],\n",
      "          [-2.1443e-02,  6.6822e-03,  1.6674e-02],\n",
      "          [ 1.4187e-03,  4.0984e-03,  2.5520e-02]],\n",
      "\n",
      "         [[-2.5661e-02, -1.2016e-02,  2.1563e-02],\n",
      "          [-6.7769e-03, -5.7781e-03,  2.5629e-03],\n",
      "          [ 3.0733e-02, -4.8856e-03, -4.8049e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7550e-03, -3.2842e-03,  2.7880e-02],\n",
      "          [ 2.9968e-02, -2.9829e-03,  1.4043e-02],\n",
      "          [-1.0089e-02,  1.2419e-04,  2.0132e-02]],\n",
      "\n",
      "         [[-7.8489e-02, -2.7586e-01, -3.4806e-02],\n",
      "          [ 5.2467e-02, -2.7630e-01, -2.5194e-01],\n",
      "          [ 2.7165e-01,  1.4819e-01, -2.3493e-02]],\n",
      "\n",
      "         [[-2.4807e-02, -2.3555e-02,  3.3474e-02],\n",
      "          [ 3.7954e-02,  1.0719e-02, -1.2034e-02],\n",
      "          [-1.1260e-03,  1.3487e-02,  2.7340e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4735e-02, -6.9496e-02,  5.4819e-02],\n",
      "          [ 2.6118e-02, -1.0451e-01, -7.3615e-02],\n",
      "          [ 1.4967e-01,  4.3769e-02, -1.3594e-01]],\n",
      "\n",
      "         [[ 2.9382e-02,  1.8569e-02,  2.0720e-02],\n",
      "          [ 5.5406e-03,  6.2317e-03,  3.7542e-02],\n",
      "          [-6.8143e-02, -3.0130e-02, -1.0179e-04]],\n",
      "\n",
      "         [[-1.7330e-02, -3.1821e-02,  4.1151e-02],\n",
      "          [ 2.0145e-02, -3.8788e-02, -9.0121e-03],\n",
      "          [ 1.4168e-02,  1.9355e-02, -1.2933e-02]]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0372, -0.1155,  0.1488, -0.1068,  0.1537, -0.0765, -0.0797, -0.2121,\n",
      "         0.0204,  0.1631,  0.0171, -0.0468,  0.0954,  0.4844,  0.1865,  0.1479,\n",
      "         0.5971, -0.2356,  0.2632,  0.5034,  0.0387,  0.5738, -0.1923, -0.1730,\n",
      "        -0.2475,  0.6164, -0.1170, -0.1255, -0.0178,  0.0288,  0.0898, -0.1468,\n",
      "         0.1985, -0.1155, -0.4822,  0.3021, -0.0195, -0.2928, -0.1937, -0.0971,\n",
      "        -0.1299, -0.1204, -0.1062, -0.4890, -0.2024,  0.0324, -0.1231, -0.2598,\n",
      "         0.2645,  0.1285,  0.3149, -1.0076,  0.4863,  0.0376,  0.0329, -0.0516,\n",
      "         0.0432, -0.4334, -0.0765, -0.2109,  0.0846,  0.1070, -0.2803, -0.3800,\n",
      "        -0.0941, -0.0064, -0.1121,  0.0981,  0.0864,  0.0349, -0.0583,  0.6763,\n",
      "         0.3148,  0.1751, -0.0770,  0.4792,  0.3607,  0.4882,  0.0723,  0.2207,\n",
      "         0.0682, -0.1710, -0.0856, -0.0314,  0.1903, -0.1361, -0.1059,  0.0186,\n",
      "         0.1025, -0.1439,  0.0394,  0.1667, -0.1913,  0.2015,  0.2098,  0.0690,\n",
      "         0.0614,  0.0973,  0.1538,  0.0796,  0.4095,  0.0895,  0.1294, -0.0296,\n",
      "        -0.0555,  0.0298, -0.0020,  0.0516, -0.1028, -0.0453,  0.3003, -0.2259,\n",
      "        -0.0129, -0.1249, -0.3595,  0.0706,  0.1441, -0.0301,  0.1717,  0.0999,\n",
      "        -0.1206, -0.0274,  0.1076,  0.0299,  0.6599, -0.0727,  0.2250,  0.2779],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in lala.gpu_layers[3].parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05e576c0-399f-4c1b-bf23-38db02b3a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "446f0134-e811-409a-be2e-0fbe61fd1dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_AlexNet = torchvision.models.alexnet(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d2f3487-72d6-4e64-acc4-afacb7e4de19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "Dropout(p=0.5, inplace=False)\n",
      "Linear(in_features=9216, out_features=4096, bias=True)\n",
      "ReLU(inplace=True)\n",
      "Dropout(p=0.5, inplace=False)\n",
      "Linear(in_features=4096, out_features=4096, bias=True)\n",
      "ReLU(inplace=True)\n",
      "Linear(in_features=4096, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "for name, child in model_AlexNet.named_children():\n",
    "    if name =='classifier':\n",
    "        print(len(layers))\n",
    "    if (type(child) != torch.nn.modules.container.Sequential):\n",
    "        layers.append(child)\n",
    "    else:\n",
    "        for layer in child:\n",
    "            layers.append(layer)\n",
    "\n",
    "for layer in layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bcab348-436d-4b50-a1c3-d686fdfe803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2ae45d3-5c16-45bc-a488-a0e3329f94de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model_GoogleNet = torchvision.models.resnet50(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edfdaa3a-b23a-413c-a2d5-91c6e338c9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "for name, child in model_GoogleNet.named_children():\n",
    "    if name =='linear' or isinstance(child,nn.Linear):\n",
    "        print(len(layers))\n",
    "    if (type(child) != torch.nn.modules.container.Sequential):\n",
    "        layers.append(child)\n",
    "    else:\n",
    "        for layer in child:\n",
    "            layers.append(layer)\n",
    "\n",
    "for layer in layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66f0f39a-b2ab-4fb8-90d6-68d84b6ea794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b956b7e-ab40-47e7-bfdf-12b0c3ff218e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=2048, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
